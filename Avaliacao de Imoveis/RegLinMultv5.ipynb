{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#Use to import pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "import matplotlib as mpl \n",
    "import matplotlib.pyplot as plt \n",
    "import itertools\n",
    "import sympy as sp\n",
    "from sympy import *\n",
    "from __future__ import division\n",
    "sp.init_printing()\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import colorama\n",
    "\n",
    "\n",
    "#Através de uma lista de varáveis explicativas retorna a regressão linear multipla\n",
    "root= tk.Tk()\n",
    "\n",
    "canvas1 = tk.Canvas(root, width = 300, height = 100, bg = 'lightsteelblue')\n",
    "canvas1.pack()\n",
    "\n",
    "def getcsv ():\n",
    "    global df1\n",
    "    root.update()\n",
    "    import_file_path = filedialog.askopenfilename()\n",
    "    root.destroy()\n",
    "    df1 = pd.read_csv (import_file_path, decimal=\",\",encoding='latin1')\n",
    "    \n",
    "browseButton_csv = tk.Button(text='Import csv File', command=getcsv, bg='green', fg='white', font=('helvetica', 12, 'bold'))\n",
    "canvas1.create_window(150, 50, window=browseButton_csv)\n",
    "\n",
    "root.mainloop()\n",
    "\n",
    "df1=df1.drop(columns=['Dado'])\n",
    "\n",
    "av=df1.iloc[-1,:] #dados do avaliando\n",
    "av=av.iloc[:-1,] #dados do avaliando retirando o valor nulo\n",
    "\n",
    "df2=df1.iloc[:-1,:] #Retirando a linha dos dados do avaliando\n",
    "\n",
    "nc,nl=df2.shape\n",
    "\n",
    "def rglmv(df2,av):\n",
    "\n",
    "    dm=df2.T\n",
    "    nc,nl=df2.shape\n",
    "\n",
    "    y=df2.iloc[:,-1] #Vetor dos valores totais 'ou unitários' \n",
    "    yt=y.T\n",
    "\n",
    "    vet=np.ones((nc,), dtype=int) #Vetor unitário a ser inserido na primeira coluna da Matriz Ddos x Variaveis=x\n",
    "    vet=(pd.DataFrame(vet)).T\n",
    "\n",
    "    xt=pd.concat([vet, dm.iloc[:-1,:]])\n",
    "\n",
    "    xt=xt.values \n",
    "    x=xt.T #Vetor das observações das variáveis explicativas\n",
    "\n",
    "    ci=np.matmul(xt,x)\n",
    "\n",
    "    c=np.linalg.inv(ci)\n",
    "    xty=np.matmul(xt,y)\n",
    "\n",
    "    b=np.matmul(c,xty) #Vetor dos coeficientes regressores\n",
    "    bt=b.T\n",
    "\n",
    "    yreg=np.matmul(b,xt) #Vetor das estimativas\n",
    "\n",
    "    ssy=np.matmul(yt,y) # Soma dos quadrados do valores\n",
    "    sse=ssy-np.matmul(np.matmul(bt,xt),y) #A soma dos quadrados do erros será\n",
    "    sso = (nc)*((np.mean(y))**2)# Soma dos quadrados do valores\n",
    "    sst = ssy-sso #Soma dos quadrados totais\n",
    "    ssr = sst-sse\n",
    "    r2=ssr/sst\n",
    "\n",
    "    gle=nc-nl\n",
    "\n",
    "    Se=math.sqrt(abs(sse/gle))\n",
    "\n",
    "    dpb=[abs(b[i]/(Se*math.sqrt(c[i][i]))) for i in range(nl)] # Valores relativos dos erros dos regressores' - Teste t\n",
    "\n",
    "    sig=[(1-stats.t.cdf(dpb[i],df=gle))*2 for i in range(nl)] # Valores das significâncias dos testes t Bicaudal\n",
    "\n",
    "    psig=max(sig)\n",
    "\n",
    "    msr=ssr/(nl-1) #Erro médio da regressão\n",
    "    mse=sse/gle #Erro médio\n",
    "    mst=sst/(nc-1) #Erro médio total\n",
    "    F=msr/mse\n",
    "\n",
    "    sigF=1-stats.f.cdf(F,dfn=nc+1,dfd=gle)\n",
    "\n",
    "    av=av.values\n",
    "    av = np.append([1],av,axis=0)\n",
    "    vav=np.matmul(b,av) #Valor estimado do imóvel\n",
    "\n",
    "    avc=np.matmul(av,c)\n",
    "    Ve=np.matmul(avc,av)*(Se**2) # Variancia da estimativa\n",
    "\n",
    "    t6=stats.t.ppf(0.9,df=gle) #Valor do p-valor para o qual a probabilidade seja menor que 80% bicaudal.\n",
    "    sic=t6*math.sqrt(Ve) #Metade do intervalo de confiança\n",
    "\n",
    "    vmin=vav-sic\n",
    "    vmax=vav+sic\n",
    "\n",
    "    ampic=2*sic/vav\n",
    "\n",
    "    return (r2,psig,ampic,b,nc,nl,gle,Se,sig,sigF,F,vav,vmin,vmax,t6,Ve,y,yreg,x,c,xt,mse,sse,sst)\n",
    "\n",
    "#....................................#Mudança de Variável\n",
    "\n",
    "exc=np.where(df2<=0)\n",
    "excl=[*exc[1]]\n",
    "rng=[*range(nl)]\n",
    "\n",
    "for i in excl:\n",
    " rng.remove(i); #Apenas as colunas que apresentam valores positivos\n",
    "\n",
    "mod=[] #Vetores que representam cada modelo\n",
    "if (nl)<=5:\n",
    "    for i in itertools.product(range(7), repeat=nl):\n",
    "         mod.append(i);\n",
    "else:\n",
    "    for i in range((7**5)*(nl)):\n",
    "         mod=np.zeros(nl).tolist()\n",
    "         mod.append(randint(0,6));\n",
    "    mod = np.reshape(mod, (nl, 7**5)).T\n",
    "    mod=mod.tolist();\n",
    "\n",
    "qtdmod=[*range(len(mod))] #Excluindo operações de mudança de variávei em numeros <= zero\n",
    "modd=[]\n",
    "for i in range(7**(nl)):\n",
    " for j in excl:\n",
    "  if mod[i][j]==1 or mod[i][j]==2 or mod[i][j]==5 or mod[i][j]==6:\n",
    "    qtdmod.remove(i);\n",
    "    \n",
    "modf=[]\n",
    "for i in qtdmod:\n",
    " modf.append(mod[i]);\n",
    "\n",
    "#Mudança de variáveis\n",
    "\n",
    "var_dict={}\n",
    "\n",
    "for k in range(len(modf)):\n",
    " df4=df2.copy()\n",
    " for i in range(nl):\n",
    "  if modf[k][i]==0:\n",
    "   df4.iloc[:,i]=df2.iloc[:,i].copy()\n",
    "  if modf[k][i]==1:\n",
    "   df4.iloc[:,i]=1/df2.iloc[:,i].copy()\n",
    "  if modf[k][i]==2:\n",
    "   df4.iloc[:,i]=np.log(df2.iloc[:,i].copy())\n",
    "  if modf[k][i]==3:\n",
    "   df4.iloc[:,i]=(df2.iloc[:,i].copy())**2\n",
    "  if modf[k][i]==4:\n",
    "   df4.iloc[:,i]=np.sqrt(df2.iloc[:,i].copy())\n",
    "  if modf[k][i]==5:\n",
    "   df4.iloc[:,i]=1/((df2.iloc[:,i].copy())**2)\n",
    "  if modf[k][i]==6:\n",
    "   df4.iloc[:,i]=1/np.sqrt(df2.iloc[:,i].copy());\n",
    "  var_dict[k] = df4;\n",
    "\n",
    "av_dict={}\n",
    "\n",
    "for k in range(len(modf)):\n",
    " df5=av.copy()\n",
    " for i in range(nl-1):\n",
    "  if modf[k][i]==0:\n",
    "   df5.iloc[:i,]=av.iloc[:i,].copy()\n",
    "  if modf[k][i]==1:\n",
    "   df5.iloc[:i,]=1/av.iloc[:i,].copy()\n",
    "  if modf[k][i]==2:\n",
    "   df5.iloc[:i,]=np.log(av.iloc[:i,].copy())\n",
    "  if modf[k][i]==3:\n",
    "   df5.iloc[:i,]=(av.iloc[:i,].copy())**2\n",
    "  if modf[k][i]==4:\n",
    "   df5.iloc[:i,]=np.sqrt(av.iloc[:i,].copy())\n",
    "  if modf[k][i]==5:\n",
    "   df5.iloc[:i,]=1/((av.iloc[:i,].copy())**2)\n",
    "  if modf[k][i]==6:\n",
    "   df5.iloc[:i,]=1/np.sqrt(av.iloc[:i,].copy());\n",
    "  av_dict[k] = df5;\n",
    "\n",
    "#...................................#\n",
    "\n",
    "rstd=rglmv(df2,av) #regressão linear sem mudança de variáveis modelo zero\n",
    "nc=rstd[4]\n",
    "nl=rstd[5]\n",
    "gle=rstd[6]\n",
    "yd=rstd[16]\n",
    "sst=rstd[23]\n",
    "\n",
    "rstd_dict={}\n",
    "\n",
    "for k in range(len(modf)):\n",
    " rstd_dict[k]=rglmv(var_dict[k],av_dict[k]);\n",
    "\n",
    "sigt_list=[]\n",
    "yest_list=[]\n",
    "filtroyneg=[] #Filtrar e evitar erros com yreg negativo de valor de imóvel\n",
    "for k in range(len(modf)):\n",
    " if modf[k][nl-1]==0: #Desfazendo a troca de variaveis para achar o valor estimado dos dados\n",
    "  yest_list.append(rstd_dict[k][17]);\n",
    "  filtroyneg.append(k)\n",
    " if modf[k][nl-1]==1:\n",
    "  yest_list.append(1/rstd_dict[k][17])\n",
    "  filtroyneg.append(k)\n",
    " if modf[k][nl-1]==2 and np.all(rstd_dict[k][17]>0):\n",
    "  yest_list.append(np.exp(rstd_dict[k][17]))\n",
    "  filtroyneg.append(k)\n",
    " if modf[k][nl-1]==3 and np.all(rstd_dict[k][17]>0):\n",
    "  yest_list.append(np.sqrt(rstd_dict[k][17]))\n",
    "  filtroyneg.append(k)\n",
    " if modf[k][nl-1]==4:\n",
    "  yest_list.append(rstd_dict[k][17]**2)\n",
    "  filtroyneg.append(k)\n",
    " if modf[k][nl-1]==5 and np.all(rstd_dict[k][17]>0):\n",
    "  yest_list.append(1/np.sqrt(rstd_dict[k][17]))\n",
    "  filtroyneg.append(k)\n",
    " if modf[k][nl-1]==6:\n",
    "  yest_list.append(1/(rstd_dict[k][17]**2))\n",
    "  filtroyneg.append(k);\n",
    "\n",
    "Eest=[]\n",
    "for k in range(len(yest_list)):\n",
    " Eest.append(yest_list[k]-yd.values);\n",
    "\n",
    "SQE_l=[]\n",
    "for k in range(len(yest_list)):\n",
    "     SQE_l.append(sum(Eest[k]*Eest[k]));\n",
    "        \n",
    "R2E_l=[]\n",
    "for k in range(len(yest_list)):\n",
    "     R2E_l.append(1-SQE_l[k]/sst);\n",
    "        \n",
    "R2E_l_ord=sorted(R2E_l, reverse=True)\n",
    "\n",
    "NtR2E_l=[] #Classificacao das determinacoes nos modelos\n",
    "for k in R2E_l:\n",
    " NtR2E_l.append(R2E_l_ord.index(k));\n",
    "\n",
    "VavE_l=[]\n",
    "filtrovav=[]\n",
    "\n",
    "for k in filtroyneg:\n",
    " if modf[k][nl-1]==0:\n",
    "  VavE_l.append(rstd_dict[k][11])\n",
    "  filtrovav.append(k)\n",
    " if modf[k][nl-1]==1:\n",
    "  VavE_l.append(1/rstd_dict[k][11])\n",
    "  filtrovav.append(k)\n",
    " if modf[k][nl-1]==2 and rstd_dict[k][11]<40:\n",
    "  VavE_l.append(np.exp(rstd_dict[k][11]))\n",
    "  filtrovav.append(k)\n",
    " if modf[k][nl-1]==3:\n",
    "  VavE_l.append(np.sqrt(rstd_dict[k][11]))\n",
    "  filtrovav.append(k)\n",
    " if modf[k][nl-1]==4:\n",
    "  VavE_l.append(rstd_dict[k][11]**2)\n",
    "  filtrovav.append(k)\n",
    " if modf[k][nl-1]==5:\n",
    "  VavE_l.append(1/np.sqrt(rstd_dict[k][11]))\n",
    "  filtrovav.append(k)\n",
    " if modf[k][nl-1]==6:\n",
    "  VavE_l.append(1/(rstd_dict[k][11]**2));\n",
    "  filtrovav.append(k);\n",
    "\n",
    "VEMin_l=[]\n",
    "VEMax_l=[]\n",
    "filtroampl=[]\n",
    "\n",
    "for k in filtrovav:\n",
    " if modf[k][nl-1]==0:\n",
    "  VEMin_l.append(rstd_dict[k][12])\n",
    "  VEMax_l.append(rstd_dict[k][13])\n",
    "  filtroampl.append(k)\n",
    " if modf[k][nl-1]==1:\n",
    "  VEMin_l.append(1/rstd_dict[k][12])\n",
    "  VEMax_l.append(1/rstd_dict[k][13])\n",
    "  filtroampl.append(k)\n",
    " if modf[k][nl-1]==2 and rstd_dict[k][13]<40:\n",
    "  VEMin_l.append(np.exp(rstd_dict[k][12]))\n",
    "  VEMax_l.append(np.exp(rstd_dict[k][13]))\n",
    "  filtroampl.append(k)\n",
    " if modf[k][nl-1]==3:\n",
    "  VEMin_l.append(np.sqrt(rstd_dict[k][12]))\n",
    "  VEMax_l.append(np.sqrt(rstd_dict[k][13]))\n",
    "  filtroampl.append(k)\n",
    " if modf[k][nl-1]==4:\n",
    "  VEMin_l.append(rstd_dict[k][12]**2)\n",
    "  VEMax_l.append(rstd_dict[k][13]**2)\n",
    "  filtroampl.append(k)\n",
    " if modf[k][nl-1]==5:\n",
    "  VEMin_l.append(1/np.sqrt(rstd_dict[k][12]))\n",
    "  VEMax_l.append(1/np.sqrt(rstd_dict[k][13]))\n",
    "  filtroampl.append(k)\n",
    " if modf[k][nl-1]==6:\n",
    "  VEMin_l.append(1/(rstd_dict[k][12]**2))\n",
    "  VEMax_l.append(1/(rstd_dict[k][13]**2))\n",
    "  filtroampl.append(k);\n",
    "\n",
    "ampl_l=[]\n",
    "filtroampl2=[]\n",
    "for k in range(len(filtroampl)):\n",
    " if VavE_l[k]>0:\n",
    "  ampl_l.append(abs(VEMax_l[k]-VEMin_l[k])/VavE_l[k])\n",
    "  filtroampl2.append(filtroampl[k]);\n",
    "    \n",
    "ampl_l_ord=sorted(ampl_l)\n",
    "\n",
    "Ntampl_l=[] #Classificacao das amplitudes nos modelos\n",
    "for k in ampl_l:\n",
    " Ntampl_l.append(ampl_l_ord.index(k));\n",
    "\n",
    "sigt_list=[]\n",
    "for k in filtroampl2:\n",
    " sigt_list.append(rstd_dict[k][1]);\n",
    "\n",
    "sigt_l_ord=sorted(sigt_list)\n",
    "\n",
    "\n",
    "Ntsigt_l=[] #Classificacao das amplitudes nos modelos\n",
    "for k in sigt_list:\n",
    " Ntsigt_l.append(sigt_l_ord.index(k));\n",
    "\n",
    "Nota=[] #combinacao da melhor determinacao, amplitude e significancia\n",
    "for k in filtroampl2:\n",
    " Nota.append(Ntsigt_l[filtroampl2.index(k)]+Ntampl_l[filtroampl2.index(k)]+NtR2E_l[filtroyneg.index(k)]);\n",
    "\n",
    "Nota_ord=sorted(Nota)\n",
    "\n",
    "modmelnota=filtroampl2[Nota.index(Nota_ord[0])] #Modelo com a melhor nota - combinacao de R2,Sigfc e Ampl\n",
    "\n",
    "Tab_fund=[] #Valor dos itens de fundamentacao \n",
    "for k in Nota_ord:\n",
    "    Tab_fund.append(k)\n",
    "    Tab_fund.append(filtroampl2[Nota.index(k)])\n",
    "    Tab_fund.append(R2E_l[filtroyneg.index(filtroampl2[Nota.index(k)])])\n",
    "    Tab_fund.append(NtR2E_l[filtroyneg.index(filtroampl2[Nota.index(k)])])\n",
    "    Tab_fund.append(sigt_list[Nota.index(k)])\n",
    "    Tab_fund.append(Ntsigt_l[Nota.index(k)])\n",
    "    Tab_fund.append(ampl_l[Nota.index(k)])\n",
    "    Tab_fund.append(Ntampl_l[Nota.index(k)]);\n",
    "\n",
    "Tab_fund = np.reshape(Tab_fund , (len(Nota_ord), 8))\n",
    "\n",
    "Tab_fund=pd.DataFrame(Tab_fund)\n",
    "\n",
    "Tab_fund.columns = ['Nota da Combinação','Nº do Modelo','R²',\n",
    "                     'Classificação do R²','Significância','Classificação da Sign.',\n",
    "                      'Amplitude do IC','Classificação da Ampl. do IC.']\n",
    "\n",
    "Tab_fund['Amplitude do IC'] = pd.Series([\"{0:.2f}%\".format(val*100) for val in Tab_fund['Amplitude do IC']])\n",
    "Tab_fund['Significância'] = pd.Series([\"{0:.2f}%\".format(val*100) for val in Tab_fund['Significância']])\n",
    "Tab_fund['R²'] = pd.Series([\"{0:.3f}\".format(val) for val in Tab_fund['R²']])\n",
    "print ('\\033[1m'+'\\033[91m'+\"Os Modelos com melhores combinações de determinação,Siginificância e Amplitude\")\n",
    "display(Tab_fund.head(10))\n",
    "\n",
    "print ('\\033[1m'+'\\033[91m'+\"Os Modelos com melhores R²\")\n",
    "Tab_fund.sort_values('Classificação do R²', inplace = True)\n",
    "display(Tab_fund.head(10))\n",
    "\n",
    "print ('\\033[1m'+'\\033[91m'+\"Os Modelso com melhores Significância\")\n",
    "Tab_fund.sort_values('Classificação da Sign.', inplace = True)\n",
    "display(Tab_fund.head(10))\n",
    "\n",
    "print ('\\033[1m'+'\\033[91m'+\"Oa Modeloa com menor amplitude de Intervalo de Confiança\")\n",
    "Tab_fund.sort_values('Classificação da Ampl. do IC.', inplace = True)\n",
    "display(Tab_fund.head(10))\n",
    "\n",
    "modesc = int(input(\"Escolha na segunda coluna das tabelas acima o modelo que considerar mais adequado\"+\n",
    "                   \" escrevendo aqui o 'Nºdo Modelo': \"));\n",
    "\n",
    "R2E=R2E_l[filtroyneg.index(modesc)]\n",
    "VavE=VavE_l[filtrovav.index(modesc)]\n",
    "VEMin=VEMin_l[filtroampl.index(modesc)]\n",
    "VEMax=VEMax_l[filtroampl.index(modesc)]\n",
    "ampl=ampl_l[filtroampl2.index(modesc)]\n",
    "sigt=sigt_list[filtroampl2.index(modesc)]\n",
    "yest=yest_list[filtroyneg.index(modesc)]\n",
    "\n",
    "r2=rstd_dict[modesc][0]\n",
    "psig=rstd_dict[modesc][1]\n",
    "b=rstd_dict[modesc][3]\n",
    "Se=rstd_dict[modesc][7]\n",
    "sig=rstd_dict[modesc][8]\n",
    "sigF=rstd_dict[modesc][9]\n",
    "F=rstd_dict[modesc][10]\n",
    "vav=rstd_dict[modesc][11]\n",
    "vmin=rstd_dict[modesc][12]\n",
    "vmax=rstd_dict[modesc][13]\n",
    "t6=rstd_dict[modesc][14]\n",
    "Ve=rstd_dict[modesc][15]\n",
    "y=rstd_dict[modesc][16]\n",
    "yreg=rstd_dict[modesc][17]\n",
    "x=rstd_dict[modesc][18]\n",
    "c=rstd_dict[modesc][19]\n",
    "xt=rstd_dict[modesc][20]\n",
    "mse=rstd_dict[modesc][21]\n",
    "sse=rstd_dict[modesc][22]\n",
    "\n",
    "print(\"O Vetor dos coeficientes regressores é\",b)\n",
    "\n",
    "t = [ '*x'+str(i) for i in range(nl)]\n",
    "\n",
    "z=[]\n",
    "# Função Condicinal para inserir sinal em elementos da string \n",
    "def adcsinal(item): \n",
    "    if int(item) >0: \n",
    "        return '+'+str(round(item,4))\n",
    "    return str(round(item,4))\n",
    "      \n",
    "z = [adcsinal(item) for item in b]\n",
    "print ('\\033[0m')\n",
    "\n",
    "y_eqest=[]\n",
    "if modf[modesc][nl-1]==0:\n",
    "    y_eqest.append('y=')\n",
    "if modf[modesc][nl-1]==1:\n",
    "    y_eqest.append('(1/y=)')\n",
    "if modf[modesc][nl-1]==2:\n",
    "    y_eqest.append('exp(y)=')\n",
    "if modf[modesc][nl-1]==3:\n",
    "    y_eqest.append('sqrt(y)=')\n",
    "if modf[modesc][nl-1]==4:\n",
    "    y_eqest.append('y**2=')\n",
    "if modf[modesc][nl-1]==5:\n",
    "    y_eqest.append('1/sqrt(y)=')\n",
    "if modf[modesc][nl-1]==6:\n",
    "    y_eqest.append('(1/y**2)=');\n",
    "\n",
    "t_est=['']\n",
    "for k in range(nl-1):\n",
    "    if modf[modesc][k]==0:\n",
    "        t_est.append('*x'+str(k+1))\n",
    "    if modf[modesc][k]==1:\n",
    "        t_est.append('*(1/x'+str(k+1)+')')\n",
    "    if modf[modesc][k]==2:\n",
    "        t_est.append('*exp(x'+str(k+1)+')')\n",
    "    if modf[modesc][k]==3:\n",
    "        t_est.append('*sqrt(x'+str(k+1)+')')\n",
    "    if modf[modesc][k]==4:\n",
    "        t_est.append('*(x'+str(k+1)+'**2)')\n",
    "    if modf[modesc][k]==5:\n",
    "        t_est.append('*1/sqrt(x'+str(k+1)+')')\n",
    "    if modf[modesc][k]==6:\n",
    "        t_est.append('*1/x'+str(k+1)+'**2');\n",
    "        \n",
    "zs=[]\n",
    "zs = [adcsinal(item) for item in b]\n",
    "\n",
    "for i in range(nl) :\n",
    "  zs[i]=zs[i]+t_est[i]; # Concatenando os coeficientes com as variaveis\n",
    "\n",
    "k_est = \"\".join(zs)\n",
    "\n",
    "m_est=str(y_eqest[0])+k_est\n",
    "\n",
    "eqe = Eq(*map(S, m_est.split('=', 1)))\n",
    "\n",
    "print ('\\033[1m'+'\\033[91m'+\"A equação da estimativa será\")\n",
    "display(eqe)\n",
    "\n",
    "if R2E < 0.6:\n",
    " r2Ev=', valor muito baixo'\n",
    "if 0.6<= R2E < 0.8:\n",
    " r2Ev=', valor aceitável'\n",
    "if 0.8<= R2E < 0.9:\n",
    " r2Ev=', valor Bom'\n",
    "else:\n",
    " r2Ev=', valor Ótimo'\n",
    "\n",
    "print (\"O coeficiente de determinação da Estimativa é R²=\",round(R2E,3),r2Ev)\n",
    "print ('\\033[0m')\n",
    "\n",
    "if r2 < 0.6:\n",
    " r2v=', valor muito baixo'\n",
    "if 0.6<= r2 < 0.8:\n",
    " r2v=', valor aceitável'\n",
    "if 0.8<= r2 < 0.9:\n",
    " r2v=', valor Bom'\n",
    "else:\n",
    " r2v=', valor Ótimo'\n",
    "\n",
    "print (\"O coeficiente de determinação da regressão é R²=\",round(r2,3),r2v)\n",
    "print ('\\033[0m')\n",
    "\n",
    "print (gle,\"Graus de Liberdade do Erro\")\n",
    "print(\"\")\n",
    "\n",
    "print (nl-1,\"Graus de Liberdade do Regressão\")\n",
    "print(\"\")\n",
    "\n",
    "print (\"O coeficiente de determinação da regressão ajustado é Ra²=\",round(1-(1-R2E)*(nc-1)/gle,3))\n",
    "print ('\\033[1m')\n",
    "print (\"O coeficiente de determinação da regressão ajustado é Ra²=\",round(1-(1-r2)*(nc-1)/gle,3))\n",
    "print ('\\033[1m')\n",
    "\n",
    "r = math.sqrt(R2E)\n",
    "\n",
    "if r == 0:\n",
    " rv=', correlação nula'\n",
    "if r > 0 and r<0.4:\n",
    " rv=', correlação fraca'\n",
    "if r >= 0.4 and r<0.7:\n",
    " rv=', correlação Média'\n",
    "if r >= 0.7 and r<0.9:\n",
    " rv=', correlação Forte'\n",
    "if r >= 0.9 and r<1:\n",
    " rv=', correlação Fortíssima'\n",
    "else:\n",
    " rv=', correlação perfeita';\n",
    "\n",
    "print (\"O coeficiente de correlação da regressão é R=\",round(r,3),rv)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "print (\"O desvio padrão da regressão é Se=\",round(Se,4))\n",
    "print(\"\")\n",
    "\n",
    "print ('\\033[91m'+\"TESTE DE HIPÓTESE DOS REGRESSORES\"'\\033[91m')\n",
    "\n",
    "sg=[(str(round(sig[i]*100,3))+\"%\") for i in range(nl)]\n",
    "\n",
    "print (\"As significâncias dos regressores são, respectivamente\",sg)\n",
    "\n",
    "sgf=[ i for i in range(nl) if sig[i]<0.05]\n",
    "\n",
    "vsig=[ (df2.columns[i-1]) for i in sgf]\n",
    "\n",
    "if len(vsig)==len(sig):\n",
    " t0=\"Todos os regressores são significante\"\n",
    " t1=\"\";\n",
    "if len(vsig)==1:\n",
    " t0=\"Apenas o regressor de:\"\n",
    " t1='é significante'\n",
    "else:\n",
    " t0=\"Apenas os regressores de:\"\n",
    " t1='são significantes';\n",
    "\n",
    "print ('\\033[1m')\n",
    "\n",
    "if sgf[0]==0:\n",
    " vsig[0]=\"constante\";\n",
    "\n",
    "vsig = \", \".join(vsig)\n",
    "print(t0,vsig,t1)\n",
    "\n",
    "ppsig=0\n",
    "for i in range(0, nl, 1) :\n",
    "    if sig[i]==psig:\n",
    "        ppsig=i;\n",
    "        ;\n",
    "if ppsig==0:\n",
    " t3=\"constante\"\n",
    "else:\n",
    " t3=\"variável \"+df2.columns[ppsig-1]\n",
    ";\n",
    "    \n",
    "t4 = \"A pior siginficância do modelo é %s%%\" % round(psig*100,3)\n",
    "\n",
    "    \n",
    "print(\"\")\n",
    "print(t4,\"do regressor da\",t3)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print ('\\033[91m'+\"TESTE DE HIPÓTESE DA REGRESSÃO\"'\\033[91m')\n",
    "\n",
    "if sigF<0.01:\n",
    " t5=\"com significância boa e menor que 1%\"\n",
    "else:\n",
    " t5=\"com significância ruim e maior que 1%\"\n",
    ";\n",
    "\n",
    "print ('\\033[0m')\n",
    "print(\"O valor de F de Fisher-Snedecor é F=\",round(F,3),t5,\",Significância =\",sigF)\n",
    "\n",
    "\n",
    "\n",
    "print ('\\033[1m')\n",
    "print(\"O valor estimado do imóvel pela estimativa é R$\",'{:,.2f}'.format(float(VavE)))\n",
    "\n",
    "print ('\\033[91m')\n",
    "print (\"VALORES MÍNIMOS E MÁXIMO NO INTERVALO DE CONFIANÇA DE 80%\")\n",
    "\n",
    "print ('\\033[0m')\n",
    "\n",
    "print(\"O valor mínimo estimado do imóvel pela regressão é R$\",'{:,.2f}'.format(float(VEMin)))\n",
    "print(\"O valor máximo estimado do imóvel pela regressão é R$\",'{:,.2f}'.format(float(VEMax)))\n",
    "\n",
    "print(\"A amplitude do intervalo de confiânça da estimativa é %s%% \" % round(100*ampl,2))\n",
    "\n",
    "print ('\\033[91m','\\033[1m')\n",
    "print (\"VALORES MÍNIMOS E MÁXIMO NO INTERVALO DE PREDIÇÃO DE 80%\")\n",
    "\n",
    "sip=t6*math.sqrt(Ve+Se**2)\n",
    "vminp=vav-sip\n",
    "vmaxp=vav+sip\n",
    "\n",
    "if modf[modesc][nl-1]==0:\n",
    " vminpE=vminp\n",
    " vmaxpE=vmaxp\n",
    "if modf[modesc][nl-1]==1:\n",
    " vminpE=(1/vminp)\n",
    " vmaxpE=(1/vmaxp)\n",
    "if modf[modesc][nl-1]==2 and vmaxp<40:\n",
    " vminpE=(np.exp(vminp))\n",
    " vmaxpE=(np.exp(vmaxp))\n",
    "if modf[modesc][nl-1]==3:\n",
    " vminpE=(np.sqrt(vminp))\n",
    " vmaxpE=(np.sqrt(vmaxp))\n",
    "if modf[modesc][nl-1]==4:\n",
    " vminpE=(vminp**2)\n",
    " vmaxpE=(vmaxp**2)\n",
    "if modf[modesc][nl-1]==5:\n",
    " vminpE=(1/np.sqrt(vminp))\n",
    " vmaxpE=(1/np.sqrt(vmaxp))\n",
    "if modf[modesc][nl-1]==6:\n",
    " vminpE=(1/(vminp**2))\n",
    " vmaxpE=(1/(vmaxp**2));\n",
    "    \n",
    "ampip=abs((vmaxpE-vminpE))/VavE\n",
    "\n",
    "if vmaxpE>vminpE:\n",
    " vmaxpE=vmaxpE\n",
    " vminpE=vminpE\n",
    "else:\n",
    " vmaxpE=vminpE\n",
    " vminpE=vmaxpE;\n",
    "    \n",
    "print ('\\033[0m')\n",
    "print(\"A amplitude do intervalo de predição é %s%% \"% round(100*ampip,2))\n",
    "print(\"O valor mínimo do intervalo de predição é R$\",'{:,.2f}'.format(float(vminpE)))\n",
    "print(\"O valor máximodo do intervalo de predição é R$\",'{:,.2f}'.format(float(vmaxpE)))\n",
    "\n",
    "print ('\\033[91m','\\033[1m')\n",
    "print (\"VALORES MÍNIMOS E MÁXIMO NO INTERVALO DE ARBÍTRIO DE 15%\")\n",
    "print ('\\033[0m')\n",
    "print(\"O valor mínimo do campo de arbítrio é R$\",'{:,.2f}'.format(float(VavE*0.85)))\n",
    "print(\"O valor máximodo do campo de arbítrio é R$\",'{:,.2f}'.format(float(VavE*1.15)))\n",
    "\n",
    "print ('\\033[91m','\\033[1m')\n",
    "print (\"ANÁLISE DE RESÍDUOS E OUTLIERS\")\n",
    "print ('\\033[0m')\n",
    "\n",
    "res=y.values-yreg #Resíduo\n",
    "rrel=res/y #Resíduo relativo aos dados\n",
    "\n",
    "rrelp=[(str(round(rrel[i]*100,3))+\"%\") for i in range(nc)]\n",
    "\n",
    "print (\"O resíduos relativos serão, respectivamente\",rrelp)\n",
    "\n",
    "rdp=res/Se #Resíduo em função do desvio da regressão - Resíduo padronizado\n",
    "\n",
    "print ('\\033[1m')\n",
    "\n",
    "print (\"O resíduos em relação ao desvio da regressão serão, respectivamente:\")\n",
    "\n",
    "print (np.round(rdp,3))\n",
    "\n",
    "otl=[ i+1 for i in range(nl) if rdp[i]>2 or rdp[i]<-2]\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (11,7)\n",
    "        \n",
    "for xn, yn in zip(yreg, rdp):\n",
    "    color = 'blue'  # non-outlier color\n",
    "    if not -2<= yn <= 2:  # condition for being an outlier\n",
    "        color = 'red'  # outlier color\n",
    "    plt.scatter(xn, yn, color=color)\n",
    "plt.plot(yreg,2*np.ones((nc), dtype=int),'r-')\n",
    "plt.plot(yreg,-2*np.ones((nc), dtype=int),'r-')\n",
    "plt.rcParams['figure.figsize'] = (11,7)\n",
    "plt.xlabel('Valores Estimados')\n",
    "plt.ylabel('Erro Padrão')\n",
    "plt.title('Homocedasticidade')\n",
    "plt.show()\n",
    "\n",
    "print ('\\033[1m')\n",
    "print (\"Ao total temos\",len(otl),\"outliers\")\n",
    "\n",
    "if len(otl)==0:\n",
    " print ('')\n",
    "else:\n",
    " print ('Os dados',otl,'são outliers');\n",
    "\n",
    "Hl=np.matmul(x,np.matmul(c,xt)) #Matriz Chapeu para identificação dos pontos de alavanca, o posto da martiz = p+1, logo observa-se o valor acima do dobro do média como possivel influenciante.\n",
    "\n",
    "dck=[ ((((res[i])**2)*Hl[i,i])/((nl)*mse*((1-Hl[i,i])**2))) for i in range(nc)] #Distância de Cook para identificação de dados influenciantes\n",
    "\n",
    "for xc, yc in zip(np.linspace(0,nc-1,nc),dck):\n",
    "    color = 'blue'  # non-outlier color\n",
    "    if not yc <= 1:  # condition for being an outlier\n",
    "        color = 'red'  # outlier color\n",
    "    plt.scatter(xc, yc, color=color)\n",
    "plt.plot(np.linspace(0,nc-1,nc),np.ones((nc), dtype=int), 'r--')\n",
    "plt.xlabel('Dados')\n",
    "plt.ylabel('Distância de Cook')\n",
    "plt.title('Análise de dados influenciantes')\n",
    "plt.show()\n",
    "\n",
    "print ('\\033[91m','\\033[1m')\n",
    "print (\"TESTE PARA O CASO DE UTILIZAÇÃO DE SÉRIES TEMPORAIS\")\n",
    "\n",
    "dw=[ ((res[i+1]-res[i])**2) for i in range(nc-1)]\n",
    "\n",
    "tdw=sum(dw)/sse\n",
    "\n",
    "dwdf = pd.read_csv ('DW.csv',decimal=\",\",encoding='latin1') #Importando dados do teste de Durbin-Watson\n",
    "dwT=dwdf.loc[(dwdf['T'])==nc]\n",
    "dwK=dwT.loc[(dwT['K'])==nl]\n",
    "dl=(dwK.loc[:'dl']).iloc[0,2]\n",
    "dh=(dwK.loc[:'dl']).iloc[0,3]\n",
    "\n",
    "print ('Os teste de Durbin-Watson teve os seguintes valores: dw=',tdw,',dl=',dl,'e dh=',dh)\n",
    "\n",
    "if 0<= tdw < dl:\n",
    " rdw='Como 0<= tdw < dl: autocorrelação positiva - Há dependência entre os resultados temporais'\n",
    "if dl<= tdw < dh:\n",
    " rdw='Como dl<= tdw < dh: Teste Inconclusivo-\"Grey Zone\"-para dependência entre os resultados temporais'\n",
    "if dh<= tdw <(4-dh):\n",
    " rdw='Como dh<= tdw <(4-dh):Não há autocorrelação de dependência entre os resultados temporais'\n",
    "if (4-dh)<= tdw <(4-dl):\n",
    " rdw='Como (4-dh)<= tdw <(4-dl): Teste Inconclusivo-\"Grey Zone\"-para dependência entre os resultados temporais'\n",
    "else:\n",
    " rdw='Como (4-dl)<= tdw <4: Indicador de significativa autocorrelação negativa';\n",
    "print ('\\033[0m')\n",
    "print (rdw)\n",
    "\n",
    "print ('\\033[91m','\\033[1m')\n",
    "print (\"ANÁLISE DE ADERÊNCIA\")\n",
    "\n",
    "#Gráfico dos valores observados x estimados\n",
    "plt.plot(yd,yd,'-y')\n",
    "scatter_plot = plt.scatter(yd,yest,alpha=0.5)\n",
    "\n",
    "from sklearn import linear_model\n",
    "model = linear_model.LinearRegression().fit(yd.values.reshape(-1, 1),yest)\n",
    "plt.plot(yd.values.reshape(-1, 1), model.predict(yd.values.reshape(-1, 1)), color='blue', linewidth=3)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.xlabel('Valores Observados')\n",
    "plt.ylabel('Valores Estimados')\n",
    "plt.title('Observados x Estimados')\n",
    "plt.rcParams['figure.figsize'] = (11,7)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Histograma dos residuos padronizados\n",
    "mu = np.mean(rdp) # média dos erros\n",
    "sigma = np.std(rdp) # Desvio padrão dos erros\n",
    "xh = rdp\n",
    "\n",
    "num_bins = 3\n",
    "\n",
    "n, bins, patches = plt.hist(xh, num_bins, density=1, facecolor='blue', alpha=0.5)\n",
    "\n",
    "xp = np.linspace(-2.32,2.32, 50)\n",
    "\n",
    "# Adicionando uma distribuição normal\n",
    "ya = norm.pdf(xp, mu, sigma)\n",
    "plt.plot(xp, ya, 'r--')\n",
    "plt.xlabel('Erros Padronizados')\n",
    "plt.ylabel('Probabilidade')\n",
    "plt.title(r'Histograma: $\\mu=$'+str(mu)+' $\\sigma=$'+str(sigma))\n",
    "\n",
    "# Ajuste do espaçamento para evitar o recorte do rótulo\n",
    "plt.subplots_adjust(left=0.15)\n",
    "plt.rcParams['figure.figsize'] = (11,7)\n",
    "plt.show()\n",
    "\n",
    "nrm1=[ i for i in range(nc) if -sigma<rdp[i]<=sigma]\n",
    "nrm2=[ i for i in range(nc) if -1.64*sigma<rdp[i]<=1.64*sigma]\n",
    "nrm3=[ i for i in range(nc) if -1.96*sigma<rdp[i]<=1.96*sigma]\n",
    "\n",
    "int1=len(nrm1)/(nc)\n",
    "int2=len(nrm2)/(nc)\n",
    "int3=len(nrm3)/(nc)\n",
    "\n",
    "print (\"A distribuição dos resíduos no intervalo de desvio padrão ]-1;+1[,]-1,64;+1,64[,]-1,96;+1,96[ são, respectivamente\",int1*100,'%,',int2*100,'%,',int3*100,'% sendo o intervalo de Distribuição Normal sugerido (66 à 75% - 85 à 95% - 95 à 100%)')\n",
    "\n",
    "if 0.66<=int1<=0.75 and 0.85<=int2<=0.95 and 0.95<=int3<=1:\n",
    " print ('Normalidade conforme a NBR-14.653-2 (A.2.1.2) está aderente')\n",
    "else:\n",
    " print ('');\n",
    "\n",
    "df3=var_dict[modesc].corr()\n",
    "\n",
    "def color_red80p(val):\n",
    "    color = 'red' if abs(val) > 0.8 else 'black'\n",
    "    return 'color: %s' % color\n",
    "\n",
    "print ('\\033[91m','\\033[1m')\n",
    "print (\"ANALISE DE CORRELAÇÃO ENTRE VARIÁVEIS ISOLADAS\")\n",
    "\n",
    "print ('\\033[1m')\n",
    "s=df3.style.applymap(color_red80p) #Analisar correlações maiores que 80%\n",
    "display(s)\n",
    "\n",
    "df3i=np.linalg.inv(df3)\n",
    "print ('\\033[91m','\\033[1m')\n",
    "print (\"ANALISE DE CORRELAÇÃO PARCIAIS COM INFLUÊNCIA\")\n",
    "\n",
    "print ('\\033[1m')\n",
    "\n",
    "corp=[]\n",
    "for k in range(nl):\n",
    "    for i in range(nl):\n",
    "        corp.append(-(df3i[i][k])/math.sqrt((df3i[i][i])*(df3i[k][k])));\n",
    "                    \n",
    "corp = np.reshape(corp , (nl, nl))\n",
    "\n",
    "corp=pd.DataFrame(corp)\n",
    "\n",
    "corp.columns=df3.columns\n",
    "corp.index=corp.columns\n",
    "\n",
    "sci=corp.style.applymap(color_red80p) #Analisar correlações maiores que 80%\n",
    "display(sci)\n",
    "\n",
    "\n",
    "print ('\\033[91m','\\033[1m')\n",
    "print (\"ANALISE DAS VARIÁVEIS MAIS RELEVANTES PARA O MODELO SEGUNDO A ANÁLISE DAS COMPONENTES PRINCIPAIS - PCA\")\n",
    "\n",
    "\n",
    "df6=df2.corr()\n",
    "ev1,ev2=np.linalg.eig((df6.iloc[:-1,:-1])) #Autovalores,Autovetores\n",
    "\n",
    "\n",
    "normaliz_df2=(df2-df2.mean())/df2.std()\n",
    "\n",
    "print (\"O autovalores que representam a variancia são:\",ev1)\n",
    "\n",
    "ev1p=ev1/sum(ev1)\n",
    "print (\"O autovalores que representam a variancia em porcentagem são:\",ev1p)\n",
    "\n",
    "sumav=0\n",
    "ndpr=0\n",
    "for k in range(nl-1):\n",
    "    if sumav<0.8:\n",
    "        sumav=sumav+ev1p[k]\n",
    "        ndpr=k+1;\n",
    "\n",
    "escor=np.matmul(normaliz_df2.iloc[:,:-1],ev2)\n",
    "\n",
    "print (\"Matriz dos escores dos dados nas direções principais\")\n",
    "escor=pd.DataFrame(escor)\n",
    "\n",
    "escor.columns=[ 'CP'+str(i) for i in range(nl-1)]\n",
    "display(escor)\n",
    "\n",
    "corlvdp=[]\n",
    "for k in range(nl-1):\n",
    "    for i in range(nl-1):\n",
    "        corlvdp.append((ev2[k][i])*sqrt(ev1[i]));\n",
    "corlvdp = np.reshape(corlvdp , (nl-1, nl-1))\n",
    "\n",
    "\n",
    "corlvdp=pd.DataFrame(corlvdp)\n",
    "\n",
    "corlvdp.columns=escor.columns\n",
    "corlvdp.index=df3.columns[:nl-1]\n",
    "\n",
    "def color_blue80p(val):\n",
    "    color = 'blue' if abs(val) > 0.8 else 'black'\n",
    "    return 'color: %s' % color\n",
    "\n",
    "print ('\\033[1m')\n",
    "print (\"A correlação das variáveis com as direções principais\")\n",
    "sdp=corlvdp.style.applymap(color_blue80p) #Analisar correlações maiores que 80% nas direções principais\n",
    "display(sdp)\n",
    "\n",
    "\n",
    "varel=np.where(abs(corlvdp.iloc[:,:ndpr])>=0.8)\n",
    "\n",
    "print ('\\033[91m','\\033[1m')\n",
    "print(\"Apenas as variáveis:\")\n",
    "for k in varel[0]:\n",
    "    print(df3.columns[:nl-1][k]);\n",
    "print(\"Tem relevância e boa correlação nas direções principais\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(escor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABoAAAASCAYAAABFGc6jAAAABHNCSVQICAgIfAhkiAAAAVxJREFUOI3t1D1LHVEQxvGfQVBSWKioVSxMp+BHEGxExEIlnWihXSDYKYLoB7AQLLSwsLO00sZCEUshoPgCSnKxSSAIiiaKb9dij3Bddr33bpPGgcMuO/+ZZ4YzO/wHq8MoVnGKG1xiByP4kBCTQz7l/C4EKwvev2ABv7CJMzSiH0voDkw+JnaJuYQirtM66kRvQuVNQTSPgYSOcmkJs9hkEJrPKlRZHAH34fmQ4KvCID7hL/awjccSc78qZl/UUVfMl5M8CD/QUa7QbAheS/BNi+62ER/RhkU84R/aSxX5FkSOUJuhuNVS4K8BPhBNXjn2OcSeFwPHAriPhjJFoCbE374FjQfoO+oziBANTR6HacBUAHYVv5PWFKYZJyHP5MvHigJgGMui+Z8XrZa45QIDM5gQraufuEILelCNdfThLp5kRvqCfDlbBXwHVnCMC9FP/QcbGIo18W7Z7RkZc2OohXYbCQAAAABJRU5ErkJggg==\n",
      "text/latex": [
       "$$25$$"
      ],
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAA4AAAASCAYAAABrXO8xAAAABHNCSVQICAgIfAhkiAAAAOlJREFUOI3N0r1KQ0EQBeDPkEJQEIyg2AipLARBUlgINhY2Fj6Eb2CvjUWw1ldJEdIIVkIiIoJFqoCIf2AliiEWu4vhcpV7wcKBZYbZOcw5h+GPookOBnjDC3o4QG18cCID/EAXN3jAFNbRwF2sB3kbJ39gcoQRTstKWI3AdmpUCgJ3Yr5KjazGFPuYxoygbyOCtvD424b7SC29FuYLsiMO7+JWcHWtDBiW8I7rskDCIYwwR3FXYTHmYfZjGQs5gIrvAzhPzerYwDaOcYY+ngVzNlEXnN7Lo7KCE1ziCZ94xQUOMVtQ0n+LLxK6LQuL4DX5AAAAAElFTkSuQmCC\n",
      "text/latex": [
       "$$3$$"
      ],
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHIAAAAVCAYAAACaLLqfAAAABHNCSVQICAgIfAhkiAAAA3VJREFUaIHt2V2MXVMUB/Bfx0RaVTNooikVQYwmElpSEoz4Gl76wrOkol5EI5G+IHReJIOQlhAkaOqVIF4oJWk6PtKHES+lNL6ioz5KVTPaqPGw9sncnpxz7mVmes7I/Sc3O2etvdf537v2Xh/70sX/GlvwIxbWTaSLY3ApJnFHJ5Mvw9+4t82825LRSaydDrtZwCPYhu8wgf0YwwacXiOvIpyFF7EXh/E1NuLUkvmvYRwntzO8Fb9hQcWcZWnOQc105BF8JH6gETyFnYLr94J/E3Ae9glerwuu76XnzxRvulVJf3+V4QvEaXy+Ys48vIs9eEwzHTm/RP6w4PvMceRShbcFn3U5+RNJ/mzJul34BieUGR5JBq6vePk9wtmDGNZMR5bhYsH3nbqJ4FzB5Sv05HSL8AcOKa5TNqS1N2WCvIEbcFSEpSIsF87ehO3/kngTsDqNn9bKInBdGreKg9GKgxjFSbiiYO1oGm/MBL0tyoW4RBzbQwWLe/EyvtUmPjcI60VR0CeKuKuEE0fqJJUwkMbdJfovMCTS3bacbmcaBzNBqyPPFDF3vMTwQ1ghfoyJzvnWivU4o+X5LazBT7WwORZ9aTxQos/k/SW6P3F2JmgNrVmF9GvBwlXiFD6ODztl2gAsEcXZEtwi8tIYVtZJqkPMS+NkiX4/FmcPrY7MTlm+4stC6m48OAME68A+0X8NiQ27pV46mDpxfSX6U3Lz8ligJDIuFd7fkZP3m2r82302tqVfP8YE18XtJs4y1iYez5Xos9akqIPoEQXSnkzQmiPHRe4YyC06jBdKXrZS5M0d+NzcCLtL03i0Vha8n8YhU47JsAhXihNX1EEMiND7SZnxV8QuOL9DMsOq+8jNSb+mQ3szgQtFTsyjx9SFwGhOt9nx58l/vxC4PenvzgS9uQmv4lbRaH45A0SzHPzXDNjqFDeLG6ftIvT8IirXa0Sx8wPuzK2pgyfchQ/wpAihu3A5rhU1yQMl64ZERHmjzPCJ4ot+3CGRYdUncgy/K78Ang1chKdF2PlZOOeA6L2GcVrBmjp4ZliGl0RqOyKu3jYp5kkURxPibrYS9wnnrJgmwX6xax6dpp3ZxlzhmWGd8M/V7SbOF7vizWm+cLVoWovyVZMwV3gSLcdeUct0hEFxMdv9Y7lZWC7Swzn10uiiiy6q8Q9N1M88TuXsrAAAAABJRU5ErkJggg==\n",
      "text/latex": [
       "$$\\left ( 4, \\quad 3, \\quad 0\\right )$$"
      ],
      "text/plain": [
       "(4, 3, 0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modf[91]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAA4AAAASCAYAAABrXO8xAAAABHNCSVQICAgIfAhkiAAAAM5JREFUOI3N0rEyQ0EUxvEfJcMVWhoZ8Qpq75PnoDJ0Kl5BK0U67yAUiUYmpZGYoRDNuePOkXszYxS+5ps95/x3Z3c//lC7uMIz3jHCOVpNUBsTzHGDU/RjfY+dOvA2hrqpfhb1y0XQfjSHWE29DUwxw7o0cBzew2cCX3GHNRxl8DD8oeYaj+GdDBbhLzVgWd/K4DKthM8zWO5YWKzN6lwVHIR3asCD8B9v0Lb8O97Ed2T9KgDlqdXInfiO3EBD5GAP1xjjA0+4wHYT9I/1BRgnMa7SDNsAAAAAAElFTkSuQmCC\n",
      "text/latex": [
       "$$0$$"
      ],
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modf[91][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
